#!/usr/bin/env python3
"""
DashboardæŒ‡æ ‡æµ‹è¯•éªŒè¯è„šæœ¬
éªŒè¯æ‰€æœ‰å…³é”®æŒ‡æ ‡æ˜¯å¦å¯ä»¥åœ¨Prometheusä¸­æŸ¥è¯¢åˆ°
"""

import requests
import json
import time

class DashboardMetricsValidator:
    def __init__(self, prometheus_url="http://localhost:9090"):
        self.prometheus_url = prometheus_url
        self.test_results = {}
    
    def query_prometheus(self, query):
        """æŸ¥è¯¢PrometheusæŒ‡æ ‡"""
        try:
            url = f"{self.prometheus_url}/api/v1/query"
            params = {"query": query}
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                if data["status"] == "success" and data["data"]["result"]:
                    return data["data"]["result"]
            return None
        except Exception as e:
            print(f"æŸ¥è¯¢é”™è¯¯: {e}")
            return None
    
    def test_topic_metrics(self):
        """æµ‹è¯•Topicç›¸å…³æŒ‡æ ‡"""
        print("ğŸ” æµ‹è¯•TopicæŒ‡æ ‡...")
        
        tests = {
            "Topicæ¶ˆæ¯æ€»æ•°": 'sum by (topic) (kafka_topic_partition_current_offset{topic!~"__.*"})',
            "Topicåˆ†åŒºæ•°": 'kafka_topic_partitions{topic!~"__.*"}',
            "æ¶ˆæ¯ç”Ÿäº§é€Ÿç‡": 'sum by (topic) (rate(kafka_topic_partition_current_offset{topic!~"__.*"}[5m]))',
            "åˆ†åŒºæ¶ˆæ¯åˆ†å¸ƒ": 'kafka_topic_partition_current_offset{topic!~"__.*"}'
        }
        
        for test_name, query in tests.items():
            result = self.query_prometheus(query)
            if result:
                self.test_results[test_name] = "âœ… é€šè¿‡"
                print(f"  âœ… {test_name}: {len(result)} ä¸ªæ•°æ®ç‚¹")
            else:
                self.test_results[test_name] = "âŒ å¤±è´¥"
                print(f"  âŒ {test_name}: æ— æ•°æ®")
    
    def test_consumer_metrics(self):
        """æµ‹è¯•Consumerç›¸å…³æŒ‡æ ‡"""
        print("\nğŸ” æµ‹è¯•ConsumeræŒ‡æ ‡...")
        
        tests = {
            "æ¶ˆè´¹è€…ç§¯å‹": 'kafka_consumer_lag_messages',
            "æ¶ˆè´¹è€…ç»„ç§¯å‹æ±‡æ€»": 'sum by (consumer_group) (kafka_consumer_lag_messages)',
            "æ¶ˆè´¹è€…å½“å‰åç§»é‡": 'kafka_consumer_current_offset',
            "æ¶ˆè´¹è€…æ—¥å¿—ç»“æŸåç§»é‡": 'kafka_consumer_log_end_offset'
        }
        
        for test_name, query in tests.items():
            result = self.query_prometheus(query)
            if result:
                self.test_results[test_name] = "âœ… é€šè¿‡"
                print(f"  âœ… {test_name}: {len(result)} ä¸ªæ•°æ®ç‚¹")
            else:
                self.test_results[test_name] = "âŒ å¤±è´¥"
                print(f"  âŒ {test_name}: æ— æ•°æ®")
    
    def test_system_metrics(self):
        """æµ‹è¯•ç³»ç»Ÿç›¸å…³æŒ‡æ ‡"""
        print("\nğŸ” æµ‹è¯•ç³»ç»ŸæŒ‡æ ‡...")
        
        tests = {
            "CPUä½¿ç”¨ç‡": '100 - (avg(irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)',
            "å†…å­˜ä½¿ç”¨ç‡": '(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100',
            "ç£ç›˜ä½¿ç”¨ç‡": '(1 - (node_filesystem_avail_bytes{fstype!="tmpfs"} / node_filesystem_size_bytes{fstype!="tmpfs"})) * 100',
            "TCPè¿æ¥æ•°": 'node_netstat_Tcp_CurrEstab',
            "ç½‘ç»œæ¥æ”¶é€Ÿç‡": 'rate(node_network_receive_bytes_total{device!="lo"}[5m])',
            "ç½‘ç»œå‘é€é€Ÿç‡": 'rate(node_network_transmit_bytes_total{device!="lo"}[5m])',
            "ç£ç›˜è¯»å–é€Ÿç‡": 'rate(node_disk_read_bytes_total[5m])',
            "ç£ç›˜å†™å…¥é€Ÿç‡": 'rate(node_disk_written_bytes_total[5m])'
        }
        
        for test_name, query in tests.items():
            result = self.query_prometheus(query)
            if result:
                self.test_results[test_name] = "âœ… é€šè¿‡"
                print(f"  âœ… {test_name}: {len(result)} ä¸ªæ•°æ®ç‚¹")
            else:
                self.test_results[test_name] = "âš ï¸  æ— æ•°æ®"
                print(f"  âš ï¸  {test_name}: æ— æ•°æ® (å¯èƒ½éœ€è¦node_exporter)")
    
    def test_jvm_metrics(self):
        """æµ‹è¯•JVMç›¸å…³æŒ‡æ ‡"""
        print("\nğŸ” æµ‹è¯•JVMæŒ‡æ ‡...")
        
        tests = {
            "JVMå †å†…å­˜ä½¿ç”¨": 'jvm_memory_heap_used_bytes',
            "JVMå †å†…å­˜æœ€å¤§": 'jvm_memory_heap_max_bytes',
            "JVMéå †å†…å­˜ä½¿ç”¨": 'jvm_memory_nonheap_used_bytes',
            "JVMåƒåœ¾å›æ”¶æ—¶é—´": 'rate(jvm_gc_collection_time_ms_total[5m])',
            "JVMåƒåœ¾å›æ”¶æ¬¡æ•°": 'rate(jvm_gc_collection_count_total[5m])',
            "JVMå½“å‰çº¿ç¨‹æ•°": 'jvm_threads_current',
            "JVMå®ˆæŠ¤çº¿ç¨‹æ•°": 'jvm_threads_daemon'
        }
        
        for test_name, query in tests.items():
            result = self.query_prometheus(query)
            if result:
                self.test_results[test_name] = "âœ… é€šè¿‡"
                print(f"  âœ… {test_name}: {len(result)} ä¸ªæ•°æ®ç‚¹")
            else:
                self.test_results[test_name] = "âš ï¸  æ— æ•°æ®"
                print(f"  âš ï¸  {test_name}: æ— æ•°æ® (å¯èƒ½éœ€è¦JMX Exporter)")
    
    def test_dashboard_queries(self):
        """æµ‹è¯•Dashboardä¸­çš„å…³é”®æŸ¥è¯¢"""
        print("\nğŸ” æµ‹è¯•Dashboardå…³é”®æŸ¥è¯¢...")
        
        dashboard_queries = {
            "é›†ç¾¤æ€»æ¶ˆæ¯æ•°": 'sum(kafka_topic_partition_current_offset{topic!~"__.*"})',
            "é›†ç¾¤Topicæ•°é‡": 'count by () (group by (topic) (kafka_topic_partitions{topic!~"__.*"}))',
            "é›†ç¾¤æ¶ˆè´¹è€…ç»„æ•°é‡": 'count by () (group by (consumer_group) (kafka_consumer_lag_messages))',
            "é›†ç¾¤æ€»ç§¯å‹": 'sum(kafka_consumer_lag_messages)',
            "é›†ç¾¤ç”Ÿäº§é€Ÿç‡": 'sum(rate(kafka_topic_partition_current_offset{topic!~"__.*"}[5m]))'
        }
        
        for test_name, query in dashboard_queries.items():
            result = self.query_prometheus(query)
            if result and len(result) > 0:
                value = result[0]["value"][1]
                self.test_results[test_name] = "âœ… é€šè¿‡"
                print(f"  âœ… {test_name}: {value}")
            else:
                self.test_results[test_name] = "âŒ å¤±è´¥"
                print(f"  âŒ {test_name}: æ— æ•°æ®")
    
    def generate_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“Š DashboardæŒ‡æ ‡éªŒè¯æŠ¥å‘Š")
        print("="*60)
        
        passed = sum(1 for result in self.test_results.values() if "âœ…" in result)
        warning = sum(1 for result in self.test_results.values() if "âš ï¸" in result)
        failed = sum(1 for result in self.test_results.values() if "âŒ" in result)
        total = len(self.test_results)
        
        print(f"æ€»æµ‹è¯•é¡¹: {total}")
        print(f"âœ… é€šè¿‡: {passed}")
        print(f"âš ï¸  è­¦å‘Š: {warning}")
        print(f"âŒ å¤±è´¥: {failed}")
        print(f"æˆåŠŸç‡: {(passed/total)*100:.1f}%")
        
        print("\nğŸ“‹ è¯¦ç»†ç»“æœ:")
        for test_name, result in self.test_results.items():
            print(f"  {result} {test_name}")
        
        print("\nğŸ’¡ å»ºè®®:")
        if failed > 0:
            print("  â€¢ æ£€æŸ¥Prometheusé…ç½®å’ŒtargetsçŠ¶æ€")
            print("  â€¢ ç¡®ä¿æ‰€æœ‰exporteræ­£å¸¸è¿è¡Œ")
        if warning > 0:
            print("  â€¢ è€ƒè™‘æ·»åŠ node_exporterè·å–ç³»ç»ŸæŒ‡æ ‡")
            print("  â€¢ è€ƒè™‘æ·»åŠ JMX exporterè·å–JVMæŒ‡æ ‡")
        if passed == total:
            print("  â€¢ ğŸ‰ æ‰€æœ‰æŒ‡æ ‡æ­£å¸¸ï¼ŒDashboardå¯ä»¥æ­£å¸¸ä½¿ç”¨ï¼")
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹DashboardæŒ‡æ ‡éªŒè¯...")
        print("="*60)
        
        self.test_topic_metrics()
        self.test_consumer_metrics()
        self.test_system_metrics()
        self.test_jvm_metrics()
        self.test_dashboard_queries()
        
        self.generate_report()

if __name__ == "__main__":
    validator = DashboardMetricsValidator()
    validator.run_all_tests()
